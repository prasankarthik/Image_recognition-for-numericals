{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prasa\\Anaconda1\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into train and test data\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Each value in x is in the form of tensor having the pixel values of an image with a number(0-9) and y is the number itself\n",
    "print(y_test)\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1efffc9dcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Showing a example image of x_train[1]\n",
    "plt.imshow(x_train[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalizing the values in the tensor and converting the pixel values to take a value between 0 and 1\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Printing and showing the normalized value\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "#Right now the input is a matrix, converting the matrix input into a flat input\n",
    "model.add(tf.keras.layers.Flatten(input_shape = x_train[0].shape))\n",
    "#Adding a layer of 128 neurons\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "#Adding another layer of 128 neurons\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "#Adding the output layer with 10 neurons(since we have only 10 possible classifications)\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))\n",
    "#Defining parameters \n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.2603 - acc: 0.9232\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1059 - acc: 0.9676\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0724 - acc: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ef830cd5c0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit(x_train,y_train,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 40us/step\n",
      "0.10115992008540779 0.9702\n"
     ]
    }
   ],
   "source": [
    "# Testing the model on the test set\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss,val_acc)\n",
    "# The model has an accuracy of 97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "model.save('num_reader.model')\n",
    "new_model = tf.keras.models.load_model('num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using the model to predict output\n",
    "predictions = new_model.predict([x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.40623207e-08 5.86549831e-08 1.40028105e-05 ... 9.99949336e-01\n",
      "  2.81335360e-07 4.31471790e-06]\n",
      " [2.99990366e-10 2.06374493e-03 9.97752011e-01 ... 1.56515606e-10\n",
      "  1.64908840e-07 1.07781535e-11]\n",
      " [7.84655043e-08 9.99912739e-01 3.31909650e-05 ... 2.62466256e-05\n",
      "  3.23706399e-06 7.32280725e-08]\n",
      " ...\n",
      " [1.02140396e-09 1.09107553e-07 7.40622008e-09 ... 3.61170942e-06\n",
      "  6.83174312e-06 2.19173562e-05]\n",
      " [2.42368799e-07 5.34295559e-08 3.50393403e-09 ... 5.44223937e-08\n",
      "  1.90855208e-04 2.14200990e-09]\n",
      " [1.77211301e-09 3.16329318e-09 1.32282096e-09 ... 6.28326005e-13\n",
      "  1.63109739e-08 7.18160698e-10]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictions is:\n",
      "2\n",
      "The image is:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ef9fd3d198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Printing the predictions\n",
    "import numpy as np\n",
    "print(\"The predictions is:\")\n",
    "print(np.argmax(predictions[1]))\n",
    "#Comparing with the picture\n",
    "print(\"The image is:\")\n",
    "plt.imshow(x_test[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
